{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Project for the EE482 course (Engineering applications in AI) in KAU\n",
    "\n",
    "The project is basically our participation in the Titanic challenge on Kaggle. The goal of the challenge is to predict weither the passenger survived or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Next segment is for loading and cleaning the data. Some features are irrelevent which will be dropped and others aren't fully complete so we need to fill them. Also, some of the data are in string so we are going to use sklearn to help us preproccess the data. We should also change some data from columns to numbers that the computer can work with. one way is by using .replace or .map and the other by the help of sklearn preprocessing feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare\n",
      "0         0       3    1  22.0      1      0   7.2500\n",
      "1         1       1    0  38.0      1      0  71.2833\n",
      "2         1       3    0  26.0      0      0   7.9250\n",
      "3         1       1    0  35.0      1      0  53.1000\n",
      "4         0       3    1  35.0      0      0   8.0500\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('dataset/train.csv')\n",
    "test = pd.read_csv('dataset/test.csv')\n",
    "passids = test[\"PassengerId\"]\n",
    "\n",
    "def cleanData(data):\n",
    "    \n",
    "\n",
    "    # Remove unwanted features\n",
    "    data = data.drop(['Name', 'Ticket', 'Cabin', 'PassengerId', \"Embarked\"], axis=1) \n",
    "\n",
    "\n",
    "    # Fill incompleted data\n",
    "    columns = ['SibSp', 'Parch', 'Fare', \"Age\"]\n",
    "    for col in columns:\n",
    "        data[col].fillna(data[col].median(), inplace=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "train = cleanData(train)\n",
    "test = cleanData(test)\n",
    "\n",
    "#Encode string data\n",
    "train['Sex'] = train['Sex'].map({'male': 1, 'female': 0})\n",
    "test['Sex'] = test['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data ready for creating the model. All we have to do is split it into training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= train['Survived']\n",
    "X = train.drop('Survived', axis = 1) # Now that we are going to split and getting ready for training we should seperate the labels and features\n",
    "\n",
    "\n",
    "X_t, X_v, y_t, y_v = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to create a multilayer neural network which is suitable for binary classification problems. After trail and error we found that these are the best hyperparameters we found.\n",
    "\n",
    "\n",
    "6 hidden layers with 5 perceptrons each  ||  Activation function -> Relu  ||  Weight optimization -> adam  ||  Learning rate -> 0.01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 82.12291%\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(5, 6), learning_rate_init=0.01, random_state=42).fit(X_t,y_t)\n",
    "\n",
    "Accuracy = mlp.score(X_v, y_v)\n",
    "print(f\"Validation accuracy: {Accuracy * 100:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = mlp.predict(test)\n",
    "\n",
    "preds = pd.DataFrame({\"PassengerId\":passids.values,\n",
    "                    \"Survived\": Submission,})\n",
    "\n",
    "preds.to_csv(\"Submission.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
